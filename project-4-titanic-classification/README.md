# ğŸš¢ Project 4: Logistic Regression on Titanic Dataset  

## ğŸ“Œ Overview  
This project applies **Logistic Regression** to the Titanic dataset to predict passenger survival.  
Building on the exploratory data analysis from **Project 3**, this project demonstrates:  

- ğŸ”¹ Data preprocessing and cleaning  
- ğŸ”¹ Feature engineering for better predictions  
- ğŸ”¹ Logistic Regression model training and evaluation  
- ğŸ”¹ Performance analysis using multiple metrics  

---

## ğŸ“‚ Dataset  
- **Source**: [Kaggle â€“ Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic/data)  
- **Files Used**:  
  - `train.csv` â†’ Training dataset with survival labels  
  - *(Optional: `test.csv` for Kaggle submission)*  

- **Target Variable**: `Survived` (0 = Did not survive, 1 = Survived)  

---

## ğŸ› ï¸ Skills Demonstrated  
- Logistic Regression (Classification)  
- Data Preprocessing & Wrangling  
- Feature Engineering & Encoding  
- Model Evaluation (Accuracy, Precision, Recall, F1-score, ROC-AUC)  
- Data Visualization (Seaborn, Matplotlib)  

---

## ğŸ” Feature Engineering  
To improve prediction power, the following features were created:  
- ğŸ‘¨â€ğŸ‘©â€ğŸ‘§ **FamilySize** = `SibSp + Parch + 1`  
- ğŸ§ **IsAlone** = 1 if passenger traveled alone, else 0  
- ğŸ·ï¸ **Title** = extracted from `Name` (Mr, Mrs, Miss, Master, Rare)  
- ğŸ‚ **AgeGroup** = binned into Child, Teen, Adult, Senior  
- ğŸ’° **FareBin** = binned into Low, Medium, High, Very High  

---

## ğŸ“Š Model Training & Evaluation  

### ğŸ”¹ Steps  
1. Preprocessed missing values (`Age`, `Embarked`) and dropped `Cabin`  
2. Encoded categorical variables with one-hot encoding  
3. Split data into training (80%) and testing (20%) sets  
4. Trained **Logistic Regression** model using scikit-learn  

### ğŸ”¹ Results (Sample Run)  
- âœ… **Accuracy**: ~80%  
- âœ… **Confusion Matrix**: Model predicts non-survivors more accurately than survivors  
- âœ… **Classification Report**:  
  - Precision (Survived = 0.77, Not Survived = 0.82)  
  - Recall (Survived = 0.74, Not Survived = 0.85)  
  - F1-Score balanced ~0.80  
- âœ… **ROC Curve & AUC**: ~0.82 (strong classification ability)  

---

## ğŸ“¦ Deliverables  
- ğŸ““ `Titanic_LogisticRegression.ipynb` â†’ Full analysis notebook  
- ğŸ“˜ `README.md` â†’ Project documentation  

*(Optional additions)*  
- ğŸ“‚ `results/` â†’ Confusion Matrix, ROC Curve plots  
- ğŸ“„ `requirements.txt` â†’ Dependencies for reproducibility  

---

## ğŸš€ How to Run  
1. Clone the repository:  
   ```bash
   git clone <your-repo-link>
   cd Titanic-LogisticRegression
